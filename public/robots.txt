# See http://www.robotstxt.org/robotstxt.html for documentation on how to use the robots.txt file

# I want web crawlers to find me so have not disallowed access.Except spider \mand

User-agent: *
Disallow:

User-agent: SpiderMan
Disallow:/
